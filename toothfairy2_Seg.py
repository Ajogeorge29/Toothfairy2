
# -*- coding: utf-8 -*-
"""ToothFairy2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_bk_ja3ucIhwON-c3yRLuWkayb58XBR
"""

import os
import json
import torch
import shutil
import numpy as np
import SimpleITK as sitk
import matplotlib.pyplot as plt
from collections import OrderedDict

# Check if GPU accelerated computing is available
assert torch.cuda.is_available(), "GPU is not available. Please enable GPU."

# Define paths for the required directories
data_path = '/workspace/nnUNet_data'
raw_data_path = os.path.join(data_path, 'nnUNet_raw')
preprocessed_path = os.path.join(data_path, 'nnUNet_preprocessed')
results_path = os.path.join(data_path, 'nnUNet_results')

# Set environment variables
os.environ['nnUNet_raw'] = raw_data_path
os.environ['nnUNet_preprocessed'] = preprocessed_path
os.environ['nnUNet_results'] = results_path

# Verify environment variables are set correctly
print("nnUNet raw data path:", os.environ['nnUNet_raw'])
print("nnUNet preprocessed data path:", os.environ['nnUNet_preprocessed'])
print("nnUNet results path:", os.environ['nnUNet_results'])

def plan_and_preprocess():
    os.system("nnUNetv2_plan_and_preprocess -d 112 -c 3d_fullres --verify_dataset_integrity")

def train():
    os.system("nnUNetv2_train 112 3d_fullres 3 -tr nnUNetTrainer_5epochs | tee train_log.txt")

def validate():
    os.system("nnUNetv2_predict -d 112 -i '/workspace/nnUNet_data/nnUNet_raw/Dataset112_ToothFairy2/imagesTs' -o '/workspace/nnunet_logs' -tr nnUNetTrainer_5epochs -c 3d_fullres -f 3")

def export_model():
    os.system("nnUNetv2_export_model_to_zip -d 112 -o '/workspace/nnunet_logs/exported_model.zip' -c 3d_fullres -tr nnUNetTrainer_5epochs -f 3 -chk model_best")

if __name__ == "__main__":
    plan_and_preprocess()
    train()
    validate()
    export_model()
